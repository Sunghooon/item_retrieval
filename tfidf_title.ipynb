{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks for Code from https://wikidocs.net/24603\n",
    "# Extracting features by using TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import collections\n",
    "from enum import Enum, auto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'shopee-product-matching/'\n",
    "train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "train = train.head(25000)\n",
    "text_train_data = train['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(list_arr):\n",
    "    idx = np.argmax(list_arr)\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding similar images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:03<00:00, 759.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Checking train_text_feature with train_text_feature\n",
    "preds = []\n",
    "CHUNK = 10\n",
    "\n",
    "print('Finding similar images...')\n",
    "CTS = (np.shape(tfidf_matrix)[0])//CHUNK\n",
    "\n",
    "if (np.shape(tfidf_matrix)[0])%CHUNK != 0:\n",
    "    CTS += 1\n",
    "distances = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "for j in tqdm(range(CTS)):\n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "\n",
    "    for k in range(b-a):\n",
    "        \n",
    "        indices = predict(distances[a + k,])\n",
    "        o = train.iloc[indices].label_group\n",
    "        preds.append(o)\n",
    "    \n",
    "train['predicted'] = preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(train):\n",
    "    #print(train)\n",
    "    label_group = train['label_group']\n",
    "    #print(label_group[25001])\n",
    "    \n",
    "    prescision = 0\n",
    "    recall = 0\n",
    "    f1_score = 0\n",
    "    for i in tqdm(range(25001, 25001 + len(label_group))):\n",
    "        #print(i)\n",
    "        query_label = label_group[i]\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        for j in range(25001, 25001 + len(train)):\n",
    "            if train['label_group'][j] == query_label or train['predicted'][j] == query_label:\n",
    "                if train['label_group'][j] == query_label and train['predicted'][j] != query_label:\n",
    "                    fn = fn + 1\n",
    "                elif train['label_group'][j] != query_label and train['predicted'][j] == query_label:\n",
    "                    fp = fp + 1\n",
    "                else:\n",
    "                    tp = tp + 1\n",
    "        if tp+fp == 0:\n",
    "            pres = 0\n",
    "        else:\n",
    "            pres = tp / (tp + fp)\n",
    "        if tp+fn == 0:\n",
    "            rec = 0\n",
    "        else:\n",
    "            rec  = tp / (tp + fn)\n",
    "        if pres + rec == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1   = 2*pres*rec / (pres + rec)\n",
    "        \n",
    "        prescision = prescision + pres\n",
    "        recall     = recall + rec\n",
    "        f1_score   = f1_score + f1\n",
    "        \n",
    "    prescision = prescision / len(label_group)\n",
    "    recall = recall / len(label_group)\n",
    "    f1_score = f1_score / len(label_group)\n",
    "    \n",
    "    return prescision, recall, f1_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape for Train Data: (25000, 21893)\n",
      "TF-IDF Matrix Shape for Test Data: (5000, 21893)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "test = test.loc[25001:30000]\n",
    "#print(test)\n",
    "text_test_data = test['title']\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(text_test_data)\n",
    "print(\"TF-IDF Matrix Shape for Train Data:\", tfidf_matrix.shape)\n",
    "print(\"TF-IDF Matrix Shape for Test Data:\", tfidf_matrix_test.shape)\n",
    "cosine_sim_mat = cosine_similarity(tfidf_matrix_test, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding similar images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 791.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Checking train_text_feature with test_text_feature\n",
    "preds = []\n",
    "CHUNK = 10\n",
    "\n",
    "print('Finding similar images...')\n",
    "CTS = (np.shape(cosine_sim_mat)[0])//CHUNK\n",
    "\n",
    "if (np.shape(cosine_sim_mat)[0])%CHUNK != 0:\n",
    "    CTS += 1\n",
    "\n",
    "for j in tqdm(range(CTS)):\n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "\n",
    "    for k in range(b-a):\n",
    "        \n",
    "        indices = predict(cosine_sim_mat[a + k,])\n",
    "        #print(indices)\n",
    "        o = train.iloc[indices].label_group\n",
    "        preds.append(o)\n",
    "    \n",
    "test['predicted'] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [02:57<00:00, 28.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5839522632922635\n",
      "0.5922\n",
      "0.5760730949557257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training dataset 에 대한 score\n",
    "# 1~25000 for train, 25001~30000 for test\n",
    "prescision, recall, f1_score = getScore(test)\n",
    "print(\"Precision: \", prescision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1-score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_process(user_input):\n",
    "    user_tfidf_matrix = tfidf_vectorizer.transform([user_input])\n",
    "    cosine_sim_mat = cosine_similarity(user_tfidf_matrix, tfidf_matrix)\n",
    "    sorted_idx = np.argsort(cosine_sim_mat)\n",
    "    sorted_arr = cosine_sim_mat[0][sorted_idx]\n",
    "    \n",
    "    print(\"[Search Result]\")\n",
    "    for i in range(5):\n",
    "        idx = sorted_idx[0][-(i+1)]\n",
    "        print(i, \") \", train['title'][idx])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search Result]\n",
      "0 )  Aero Bed/ Car Air Bed / Kasur Angin Mobil / Kasur Angin Portable mobil E-3 FREE POMPA ANGIN\n",
      "1 )  b\"Kintakun D'Luxe Bed Cover Set New Winter Minimalis Edition Uk. 180x200\"\n",
      "2 )  KASUR BAYI LIPAT KELAMBU BOAT MODEL, BED COVER MOTIF NAVY YELLOW  PERLENGKAPAN BAYI\n",
      "3 )  Bestway 67002 Kasur Angin Double Biru [191cm x 137cm] / Air Bed Double\n",
      "4 )  EDW 501 Bamboo Storage Jumbo 65 Liter Box 3 Sekat Organizer Pakaian, Selimut, Bed Cover, Sprei\n"
     ]
    }
   ],
   "source": [
    "user_input = \"bed\"\n",
    "user_process(user_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using SVM model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=1.0)\n",
    "svm_model.fit(tfidf_matrix, train['label_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(tfidf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
